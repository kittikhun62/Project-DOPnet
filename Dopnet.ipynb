{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNSLoQi39fCZvI+NqMpo7Mv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittikhun62/Project-DOPnet/blob/main/Dopnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2l4Ow1Sz4VJ"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "import itertools\n",
        "import pandas\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import util.autoencoder as ae\n",
        "import util.dopnet as dp"
      ],
      "metadata": {
        "id": "NEzjT0S10Xnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from util.ml import get_k_folds_list\n"
      ],
      "metadata": {
        "id": "GB688hlT0SzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbsIpe-70Sb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment settings\n",
        "dataset_path = 'dataset/mrl.xlsx'\n",
        "target_idx = 5\n",
        "max_dops = 3\n",
        "init_lr = 1e-1\n",
        "n_folds = 3\n"
      ],
      "metadata": {
        "id": "4MWvxkSX0GYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "dataset = dp.load_dataset(dataset_path, comp_idx=0, target_idx=6, max_dops=max_dops, cond_idx=[1])\n",
        "rand_idx = numpy.random.permutation(len(dataset))\n",
        "rand_dataset = [dataset[idx] for idx in rand_idx]\n",
        "k_folds = get_k_folds_list(rand_dataset, k=n_folds)\n"
      ],
      "metadata": {
        "id": "H1-d67od0GVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list objects storing prediction results\n",
        "list_test_mae = list()\n",
        "list_test_rmse = list()\n",
        "list_test_r2 = list()\n",
        "list_preds = list()\n",
        "list_embs = list()"
      ],
      "metadata": {
        "id": "hF_E1cVI0GTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and evaluate DopNet for k-fold dataset\n",
        "for k in range(0, n_folds):\n",
        "    print('---------------------- Fold [{}/{}] ----------------------'.format(k + 1, n_folds))\n",
        "\n",
        "    # load training dataset\n",
        "    dataset_train = list(itertools.chain(*(k_folds[:k] + k_folds[k + 1:])))\n",
        "    comps_train = [x.comp for x in dataset_train]\n",
        "    targets_train = numpy.array([x.target for x in dataset_train]).reshape(-1, 1)\n",
        "    dop_dataset_train = dp.get_dataset(dataset_train, max_dops)\n",
        "    data_loader_train = DataLoader(dop_dataset_train, batch_size=32, shuffle=True)\n",
        "    data_loader_calc = DataLoader(dop_dataset_train, batch_size=32)"
      ],
      "metadata": {
        "id": "CZRS_pTn0GRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load test dataset\n",
        "    dataset_test = k_folds[k]\n",
        "    comps_test = [x.comp for x in dataset_test]\n",
        "    targets_test = numpy.array([x.target for x in dataset_test]).reshape(-1, 1)\n",
        "    dop_dataset_test = dp.get_dataset(dataset_test, max_dops)\n",
        "    data_loader_test = DataLoader(dop_dataset_test, batch_size=32)\n"
      ],
      "metadata": {
        "id": "2YIKmce90GO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define host embedding network and its optimizer\n",
        "    emb_host = ae.Autoencoder(dataset[0].host_feat.shape[0], 64).cuda()\n",
        "    optimizer_emb = torch.optim.Adam(emb_host.parameters(), lr=1e-3, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "_0Q72U4Y0GMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # train the host embedding network\n",
        "    for epoch in range(0, 300):\n",
        "        train_loss = ae.train(emb_host, data_loader_train, optimizer_emb)\n",
        "        print('Epoch [{}/{}]\\tTrain loss: {:.4f}'.format(epoch + 1, 300, train_loss))\n"
      ],
      "metadata": {
        "id": "jYcSBlG80GKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # calculate host embeddings\n",
        "    host_embs_train = ae.test(emb_host, data_loader_calc)\n",
        "    host_embs_test = ae.test(emb_host, data_loader_test)\n"
      ],
      "metadata": {
        "id": "vBxsNa-X0GIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # load dataset for DopNet\n",
        "    dop_dataset_train.host_feats = host_embs_train\n",
        "    dop_dataset_test.host_feats = host_embs_test\n",
        "    data_loader_train = DataLoader(dop_dataset_train, batch_size=32, shuffle=True)\n",
        "    data_loader_calc = DataLoader(dop_dataset_train, batch_size=32)\n",
        "    data_loader_test = DataLoader(dop_dataset_test, batch_size=32)"
      ],
      "metadata": {
        "id": "2ob4bB5U0GF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define DopNet and its optimizer\n",
        "    pred_model = dp.DopNet(host_embs_train.shape[1], dataset[0].dop_feats.shape[1], dim_out=1, max_dops=max_dops).cuda()\n",
        "    optimizer = torch.optim.SGD(pred_model.parameters(), lr=init_lr, weight_decay=1e-7)\n",
        "    criterion = torch.nn.L1Loss()"
      ],
      "metadata": {
        "id": "bGveGfIW0GDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train DopNet\n",
        "    for epoch in range(0, 600):\n",
        "        if (epoch + 1) % 200 == 0:\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] *= 0.5\n",
        "\n",
        "        train_loss = dp.train(pred_model, data_loader_train, optimizer, criterion)\n",
        "        preds_test = dp.test(pred_model, data_loader_test).cpu().numpy()\n",
        "        test_loss = mean_absolute_error(targets_test, preds_test)\n",
        "        print('Epoch [{}/{}]\\tTrain loss: {:.4f}\\tTest loss: {:.4f}'.format(epoch + 1, 600, train_loss, test_loss))\n"
      ],
      "metadata": {
        "id": "ZRFNfNW50GBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # calculate predictions, embeddings, and evaluation metrics\n",
        "    preds_test = dp.test(pred_model, data_loader_test).cpu().numpy()\n",
        "    embs_test = dp.emb(pred_model, data_loader_test).cpu().numpy()\n",
        "    list_test_mae.append(mean_absolute_error(targets_test, preds_test))\n",
        "    list_test_rmse.append(numpy.sqrt(mean_squared_error(targets_test, preds_test)))\n",
        "    list_test_r2.append(r2_score(targets_test, preds_test))"
      ],
      "metadata": {
        "id": "kcwSWciG0F_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save prediction and embedding results to the list objects\n",
        "    idx_test = numpy.array([x.idx for x in dataset_test]).reshape(-1, 1)\n",
        "    list_preds.append(numpy.hstack([idx_test, targets_test, preds_test]))\n",
        "    list_embs.append(numpy.hstack([idx_test, targets_test, embs_test]))\n"
      ],
      "metadata": {
        "id": "bpmujmoj0F9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save prediction end embedding results as files\n",
        "pandas.DataFrame(numpy.vstack(list_preds)).to_excel('save/pred/preds_dopnet.xlsx', header=None, index=None)\n",
        "pandas.DataFrame(numpy.vstack(list_embs)).to_excel('save/emb/embs_dopnet.xlsx', header=None, index=None)\n"
      ],
      "metadata": {
        "id": "Y1V3Hd_a0F7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print evaluation results\n",
        "print('Test MAE: ' + str(numpy.mean(list_test_mae)))\n",
        "print('Test RMSE: ' + str(numpy.mean(list_test_rmse)))\n",
        "print('Test R2: ' + str(numpy.mean(list_test_r2)))"
      ],
      "metadata": {
        "id": "FzkEa8SR0F4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QvsuG9P0Fyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}